---
permalink: /zh/
title: ""
excerpt: ""
author_profile: true
layout: default
---

<h1>ä¸ªäººç®€ä»‹</h1>

<span class='anchor' id='about-me'></span>

<span style="float: right; margin-top: -30px;"><a href="/">English</a></span>

<p>æ‚¨å¥½ï¼æˆ‘æ˜¯ç‹å­æ³°ï¼ˆè‹±æ–‡åï¼šZitai Wangï¼Œé‚®ç®±ï¼šwangzitai@ict.ac.cnï¼‰ã€‚æˆ‘ç›®å‰æ˜¯ä¸­å›½ç§‘å­¦é™¢è®¡ç®—æŠ€æœ¯ç ”ç©¶æ‰€çš„åšå£«åç ”ç©¶å‘˜ã€‚æˆ‘åœ¨ä¸­å›½ç§‘å­¦é™¢ä¿¡æ¯å·¥ç¨‹ç ”ç©¶æ‰€è·å¾—åšå£«å­¦ä½ï¼Œå¯¼å¸ˆæ˜¯<a href="https://qmhuang-ucas.github.io/">é»„åº†æ˜æ•™æˆ</a>ï¼ˆIEEE Fellowï¼‰ã€‚æˆ‘ä¹Ÿå¾ˆå¹¸è¿èƒ½å¤Ÿä¸<a href="https://qianqianxu010.github.io/">è®¸å€©å€©æ•™æˆ</a>ï¼ˆä¸­ç§‘é™¢è®¡ç®—æ‰€æ•™æˆï¼‰ã€<a href="http://people.ucas.ac.cn/~xiaochun">æ“æ™“æ˜¥æ•™æˆ</a>ï¼ˆä¸­å±±å¤§å­¦æ·±åœ³æ ¡åŒºæ•™æˆï¼‰ã€<a href="https://scholar.google.com/citations?user=cWbXLzgAAAAJ&hl=zh-CN">ä½•æºåšå£«</a>ï¼ˆå¯å…ƒå®éªŒå®¤ï¼‰ã€<a href="https://joshuaas.github.io/">æ¨æ™ºå‹‡å‰¯æ•™æˆ</a>ï¼ˆä¸­ç§‘é™¢å¤§å­¦å‰¯æ•™æˆï¼‰ã€<a href="https://www.researchgate.net/profile/Ke_Ma10">é©¬å·å‰¯æ•™æˆ</a>ï¼ˆä¸­ç§‘é™¢å¤§å­¦å‰¯æ•™æˆï¼‰ä»¥åŠ<a href="https://jiangyangby.github.io/">å§œé˜³é‚¦å½¦åšå£«</a>ï¼ˆä¸­ç§‘é™¢å¤§å­¦åšå£«åï¼‰ç­‰å­¦è€…åˆä½œã€‚</p>

<p>æˆ‘çš„ç ”ç©¶å…´è¶£åŒ…æ‹¬æœºå™¨å­¦ä¹ å’Œæ•°æ®æŒ–æ˜ã€‚æˆ‘å·²å‘è¡¨æˆ–åˆä½œå‘è¡¨äº†10å¤šç¯‡å­¦æœ¯è®ºæ–‡ï¼Œå‘è¡¨åœ¨é¡¶çº§å›½é™…ä¼šè®®å’ŒæœŸåˆŠä¸Šï¼ŒåŒ…æ‹¬T-PAMIã€IJCVã€ICMLã€NeurIPSã€AAAIå’ŒACM Multimediaã€‚</p>

<h1>ğŸ“ å­¦æœ¯è®ºæ–‡</h1>

<span class='anchor' id='-publications'></span>

<h2>2025å¹´</h2>

<p><a href="https://arxiv.org/pdf/2505.04560">ABKD: Pursuing a Proper Allocation of the Probability Mass in Knowledge Distillation via Î±-Î²-Divergence</a></p>

<p>Guanghui Wang, Zhiyong Yang, <strong>Zitai Wang</strong>, Shi Wang, Qianqian Xu, Qingming Huang. ABKD: Pursuing a Proper Allocation of the Probability Mass in Knowledge Distillation via Î±-Î²-Divergence. International Conference on Machine Learning (<strong>ICML</strong>), 2025. (<strong><font color='red'>Oral, 1.0%</font></strong>, Accepted) | <a href="https://github.com/ghwang-s/abkd">[Code]</a></p>

<p><a href="https://arxiv.org/abs/2505.05180">OpenworldAUC: Towards Unified Evaluation and Optimization for Open-world Prompt Tuning</a></p>

<p>Cong Hua, Qianqian Xu, Zhiyong Yang, <strong>Zitai Wang</strong>, Shilong Bao, Qingming Huang. OpenworldAUC: Towards Unified Evaluation and Optimization for Open-world Prompt Tuning. International Conference on Machine Learning (<strong>ICML</strong>), 2025. (Accepted) <a href="https://github.com/huacong/OpenworldAUC">[Code]</a></p>

<p><a href="https://arxiv.org/abs/2505.01660">Focal-SAM: Focal Sharpness-Aware Minimization for Long-Tailed Classification</a></p>

<p>Sicong Li, Qianqian Xu, Zhiyong Yang, <strong>Zitai Wang</strong>, Linchao Zhang, Xiaochun Cao, Qingming Huang. Focal-SAM: Focal Sharpness-Aware Minimization for Long-Tailed Classification. International Conference on Machine Learning (<strong>ICML</strong>), 2025. (Accepted) | <a href="https://github.com/scongl/Focal-SAM">[Code]</a></p>

<p><a href="https://arxiv.org/pdf/2412.07499">EDGE: Unknown-aware Multi-label Learning by Energy Distribution Gap Expansion</a></p>

<p>Yuchen Sun, Qianqian Xu, <strong>Zitai Wang</strong>, Zhiyong Yang, Junwei He. EDGE: Unknown-aware Multi-label Learning by Energy Distribution Gap Expansion. AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 12613-12621, 2025. | <a href="https://github.com/Yuchen-Sunflower/EDGE">[Code]</a></p>

<h2>2024å¹´</h2>

<p><a href="https://arxiv.org/abs/2407.06709">Top-K Pairwise Ranking: Bridging the Gap Among Ranking-Based Measures for Multi-Label Classification</a></p>

<p><strong>Zitai Wang,</strong> Qianqian Xu, Zhiyong Yang, Peisong Wen, Yuan He, Xiaochun Cao, Qingming Huang. Top-K Pairwise Ranking: Bridging the Gap Among Ranking-Based Measures for Multi-Label Classification. International Journal of Computer Vision <strong><font color='red'>(IJCV, IF: 11.6)</font></strong>, 133(1): 211-253, Jan. 2025.</p>

<p><a href="https://arxiv.org/abs/2405.07780">Harnessing Hierarchical Label Distribution Variations in Test Agnostic Long-tail Recognition</a></p>

<p>Zhiyong Yang, Qianqian Xu, <strong>Zitai Wang</strong>, Sicong Li, Boyu Han, Shilong Bao, Xiaochun Cao, Qingming Huang. Harnessing Hierarchical Label Distribution Variations in Test Agnostic Long-tail Recognition. International Conference on Machine Learning (<strong>ICML</strong>), 56624-56664, 2024. | <a href="https://github.com/scongl/DirMixE">[Code]</a> | <a href="https://youtu.be/oo2oFO0v_rM?si=_vcyqdWLtkzcvcjg">[Video]</a></p>

<p><a href="https://arxiv.org/abs/2410.03558">Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features</a></p>

<p>Benyuan Meng, Qianqian Xu, <strong>Zitai Wang</strong>, Xiaochun Cao, Qingming Huang. Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features. Annual Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 55141-55177, 2024. <strong><font color='red'> (Spotlight, 2.1%)</font></strong> | <a href="https://github.com/Darkbblue/generic-diffusion-feature">[Code]</a></p>

<p><a href="https://arxiv.org/abs/2410.06719">Suppress Content Shift: Better Diffusion Features via Off-the-Shelf Generation Techniques</a></p>

<p>Benyuan Meng, Qianqian Xu, <strong>Zitai Wang</strong>, Zhiyong Yang, Xiaochun Cao, Qingming Huang. Suppress Content Shift: Better Diffusion Features via Off-the-Shelf Generation Techniques. Annual Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 18910-18939, 2024. <a href="https://github.com/Darkbblue/diffusion-content-shift">[Code]</a></p>

<p><a href="https://arxiv.org/abs/2312.14535">ADA-GAD: Anomaly-Denoised Autoencoders for Graph Anomaly Detection</a></p>

<p>Junwei He, Qianqian Xu, Yangbangyan Jiang, <strong>Zitai Wang</strong>, Qingming Huang. ADA-GAD: Anomaly-Denoised Autoencoders for Graph Anomaly Detection. AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 8481-8489, 2024. | <a href="https://github.com/jweihe/ADA-GAD">[Code]</a></p>

<p><a href="https://arxiv.org/abs/2407.21742">HGOE: Hybrid External and Internal Graph Outlier Exposure for Graph Out-of-Distribution Detection</a></p>

<p>Junwei He, Qianqian Xu, Yangbangyan Jiang, <strong>Zitai Wang</strong>, Yuchen Sun, Qingming Huang. HGOE: Hybrid External and Internal Graph Outlier Exposure for Graph Out-of-Distribution Detection. ACM Conference on Multimedia (<strong>ACM MM</strong>), 1544-1553, 2024. | <a href="https://github.com/jweihe/HGOE">[Code]</a></p>

<h2>å†å²è®ºæ–‡</h2>

<p><a href="https://arxiv.org/pdf/2209.01398">Optimizing Partial Area Under the Top-k Curve: Theory and Practice</a></p>

<p><strong>Zitai Wang</strong>, Qianqian Xu, Zhiyong Yang, Yuan He, Xiaochun Cao and Qingming Huang. Optimizing Partial Area Under the Top-k Curve: Theory and Practice. IEEE Transactions on Pattern Analysis and Machine Intelligence <strong><font color='red'>(TPAMI, IF: 18.6)</font></strong>, 45(4): 5053-5069, Apr. 2023. | <a href="https://github.com/wang22ti/AUTKC-optimization">[Code]</a></p>

<p><a href="https://arxiv.org/abs/2310.04752">A Unified Generalization Analysis of Re-Weighting and Logit-Adjustment for Imbalanced Learning</a></p>

<p><strong>Zitai Wang</strong>, Qianqian Xu, Zhiyong Yang, Yuan He, Xiaochun Cao and Qingming Huang. A Unified Generalization Analysis of Re-Weighting and Logit-Adjustment for Imbalanced Learning. Annual Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 48417-48430, 2023. <strong><font color='red'> (Spotlight, 3.1%) </font></strong> | <a href="https://github.com/wang22ti/DDC">[Code]</a> | <a href="https://recorder-v3.slideslive.com/#/share?share=86894&s=aa1e5d66-3548-4059-be25-69a624cf27cd">[Video]</a> | <a href="https://neurips.cc/media/neurips-2023/Slides/71523.pdf">[Slides]</a></p>

<p><a href="https://arxiv.org/pdf/2210.13458">OpenAUC: Towards AUC-Oriented Open-Set Recognition</a></p>

<p><strong>Zitai Wang</strong>, Qianqian Xu, Zhiyong Yang, Yuan He, Xiaochun Cao and Qingming Huang. OpenAUC: Towards AUC-Oriented Open-Set Recognition. Annual Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 25033-25045, 2022. <strong><font color='red'> (Spotlight, 5.4%) </font></strong> | <a href="https://github.com/wang22ti/OpenAUC">[Code]</a> | <a href="https://nips.cc/virtual/2022/poster/55414">[Video]</a> | <a href="https://nips.cc/media/PosterPDFs/NeurIPS%202022/55414.png?t=1669819483.1968117">[Poster]</a> | <a href="https://nips.cc/media/neurips-2022/Slides/55414.pdf">[Slides]</a></p>

<p><a href="https://github.com/wang22ti/Confederated-Learning/blob/main/mmfp1684-wang.pdf">Confederated Learning: Going Beyond Centralization</a></p>

<p><strong>Zitai Wang,</strong> Qianqian Xu, Ke Ma, Xiaochun Cao and Qingming Huang. Confederated Learning: Going Beyond Centralization. ACM Conference on Multimedia (<strong>ACM MM</strong>), 2939-2947, 2022. <strong><font color='red'> (Oral, 5.6%) </font></strong> | <a href="https://github.com/wang22ti/Confederated-Learning">[Code]</a> | <a href="https://github.com/wang22ti/Confederated-Learning/blob/main/MM2022_slides.pdf">[Slides]</a></p>

<h1>ğŸ’» é¡¹ç›®ä¸èµ„åŠ©</h1>

<span class='anchor' id='-projects--fundings'></span>
<ul>
<li><em>2025å¹´</em> ä¸­å›½åšå£«åç§‘å­¦åŸºé‡‘é¢ä¸Šèµ„åŠ©</li>
<li><em>2025å¹´</em> åŒ—äº¬å¸‚è‡ªç„¶ç§‘å­¦åŸºé‡‘-æµ·æ·€åŸå§‹åˆ›æ–°è”åˆåŸºé‡‘åŸ¹è‚²é¡¹ç›®</li>
<li><em>2025å¹´</em> ä¸­å›½ç§‘å­¦é™¢ç‰¹åˆ«ç ”ç©¶åŠ©ç†èµ„åŠ©é¡¹ç›®</li>
<li><em>2024å¹´</em> åšå£«ååˆ›æ–°äººæ‰æ”¯æŒè®¡åˆ’</li>
</ul>

<h1>ğŸ– è£èª‰ä¸å¥–åŠ±</h1>

<span class='anchor' id='-honors--awards'></span>
<ul>
<li><em>2025å¹´</em> ç¬¬ä¸‰å±ŠCVPRç»„åˆå¼3Dè§†è§‰ç ”è®¨ä¼šä¸€ç­‰å¥–ï¼ˆç²—ç²’åº¦GCRèµ›é“ï¼‰</li>
<li><em>2025å¹´</em> ICLR 2025ä¼˜ç§€å®¡ç¨¿äººï¼ˆ480/å…¨éƒ¨ï¼‰</li>
<li><em>2024å¹´</em> NeurIPS 2024ä¼˜ç§€å®¡ç¨¿äººï¼ˆ1304/15160ï¼Œ8.6%ï¼‰</li>
<li><em>2024å¹´</em> ä¸­å›½ç§‘å­¦é™¢é™¢é•¿ä¼˜ç§€å¥–</li>
<li><em>2024å¹´</em> åŒ—äº¬å¸‚ä¼˜ç§€æ¯•ä¸šç”Ÿï¼Œä¸­å›½ç§‘å­¦é™¢å¤§å­¦ä¼˜ç§€æ¯•ä¸šç”Ÿ</li>
<li><em>2023å¹´</em> å›½å®¶å¥–å­¦é‡‘ï¼Œä¸­åäººæ°‘å…±å’Œå›½æ•™è‚²éƒ¨</li>
<li><em>2021å¹´</em> ä¸­å›½ç§‘å­¦é™¢ä¿¡å·¥æ‰€æ‰€é•¿ä¼˜ç§€å¥–</li>
<li><em>2019å¹´</em> åŒ—äº¬å¸‚ä¼˜ç§€æ¯•ä¸šç”Ÿï¼ŒåŒ—äº¬äº¤é€šå¤§å­¦ä¼˜ç§€æ¯•ä¸šç”Ÿ</li>
</ul>

<h1>ğŸ’¬ å—é‚€æŠ¥å‘Šä¸æ¼”è®²</h1>

<span class='anchor' id='-invited-talks--presentations'></span>
<ul>
<li><em>2024å¹´1æœˆ</em>: &nbsp; TechBeatæŠ€æœ¯å…¬å¼€è¯¾NeurIPS 2023è®ºæ–‡è§£è¯». <a href="https://www.techbeat.net/talk-info?id=846">[è§†é¢‘]</a>.</li>
<li><em>2023å¹´12æœˆ</em>: &nbsp; AI TIME NeurIPS 2023è®ºæ–‡è§£è¯». <a href="https://mp.weixin.qq.com/s/ur6aB8ojkmlhgtW-bIxLXw">[é¡µé¢]</a>.</li>
<li><em>2023å¹´12æœˆ</em>: &nbsp; ä¸­å›½å›¾è±¡å›¾å½¢å­¦å­¦ä¼šé’å¹´ç§‘å­¦å®¶è®ºå›. <a href="https://github.com/wang22ti/OpenAUC/blob/main/CSIG%20youth%20poster%20-%20OpenAUC.jpg">[æµ·æŠ¥]</a>.</li>
<li><em>2023å¹´10æœˆ</em>: &nbsp; PRCV 2023åšå£«ç”Ÿè®ºå›. <a href="https://mp.weixin.qq.com/s/2mSlWBu7NYo88SjFD8Wn8Q">[é¡µé¢]</a>.</li>
<li><em>2023å¹´2æœˆ</em>: &nbsp; AI TIMEé’å¹´ç§‘å­¦å®¶NeurIPS 2022è®ºæ–‡è§£è¯». <a href="https://www.bilibili.com/video/BV1624y1G7un/?spm_id_from=333.999.0.0&vd_source=356f7336a633368638ff41a90a11197b">[è§†é¢‘]</a>.</li>
</ul>

<h1>ğŸ“– å­¦æœ¯æœåŠ¡</h1>

<span class='anchor' id='-academic-services'></span>
<h2>æœŸåˆŠå®¡ç¨¿</h2>
<ul>
<li>IEEE Transactions on Pattern Analysis and Machine Intelligence (<em>IEEE T-PAMI</em>): å®¡ç¨¿äºº</li>
<li>IEEE Transactions on Image Processing (<em>IEEE T-IP</em>): å®¡ç¨¿äºº</li>
<li>IEEE Transactions on Knowledge and Data Engineering (<em>IEEE T-KDE</em>): å®¡ç¨¿äºº</li>
<li>IEEE Transactions on Circuits and Systems for Video Technology (<em>IEEE T-CSVT</em>): å®¡ç¨¿äºº</li>
<li>IEEE Transactions on Multimedia (<em>IEEE T-MM</em>): å®¡ç¨¿äºº</li>
<li>Transactions on Machine Learning Research (<em>TMLR</em>): å®¡ç¨¿äºº</li>
<li>Pattern Recognition (<em>PR</em>): å®¡ç¨¿äºº</li>
<li>Machine Learning (<em>ML</em>): å®¡ç¨¿äºº</li>
</ul>

<h2>ä¼šè®®å®¡ç¨¿</h2>
<ul>
<li><em>ICML</em>: ç¨‹åºå§”å‘˜ä¼šå§”å‘˜ (2025)</li>
<li><em>NeurIPS</em>: ç¨‹åºå§”å‘˜ä¼šå§”å‘˜ (2024, 2025)</li>
<li><em>ICLR</em>: ç¨‹åºå§”å‘˜ä¼šå§”å‘˜ (2025)</li>
<li><em>CVPR</em>: ç¨‹åºå§”å‘˜ä¼šå§”å‘˜ (2024, 2025)</li>
<li><em>ICCV</em>: ç¨‹åºå§”å‘˜ä¼šå§”å‘˜ (2025)</li>
<li><em>AISTATS</em>: ç¨‹åºå§”å‘˜ä¼šå§”å‘˜ (2025, 2026)</li>
<li><em>AAAI</em>: ç¨‹åºå§”å‘˜ä¼šå§”å‘˜ (2023, 2024, 2025, 2026)</li>
<li><em>IJCAI</em>: ç¨‹åºå§”å‘˜ä¼šå§”å‘˜ (2025)</li>
<li><em>ACM MM</em>: ç¨‹åºå§”å‘˜ä¼šå§”å‘˜ (2023, 2024, 2025)</li>
<li><em>ICDE</em>: ç¨‹åºå§”å‘˜ä¼šå§”å‘˜ (2024)</li>
<li><em>ACML</em>: ç¨‹åºå§”å‘˜ä¼šå§”å‘˜ (2024, 2025)</li>
</ul>

<h1>ğŸŒ è¯­è¨€ç‰ˆæœ¬</h1>

<span class='anchor' id='-language'></span>
<ul>
<li><a href="/"><strong>è‹±æ–‡ç‰ˆ</strong></a></li>
</ul>
